{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction using SAVIME and PYSAVIME\n",
    "\n",
    "__The goal of this notebook is to introduce the model execution and prediction feature, using the Savime system and the PySavime access API. The models and data used will be the ones created in the first notebook: Part-01.\n",
    "\n",
    "Check the variables `savime_host` and `savime_port`, which point to the host and port where Savime is listening to, respectively. We assume Savime is initialized, and Tfx is listening to the port 8501. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if not 'notebooks' in os.listdir('.'):\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "# We define the data file path : a json storing information about \n",
    "# the x and y partitions used in part-01.\n",
    "    \n",
    "data_file = 'saved_models_elastic_net/data.json'\n",
    "\n",
    "# Configuring host and port where Savime is listening to\n",
    "savime_host = '127.0.0.1'\n",
    "savime_port = 65000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we include the necessary modules. Note the pysavime package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Savime imports\n",
    "import pysavime\n",
    "from pysavime.util.converter import DataVariableBlockConverter\n",
    "from pysavime.util.data_variable import DataVariableBlockOps\n",
    "\n",
    "# Importing Python prediction client for Tfx\n",
    "from src.predictor_consumer import PredictionConsumer\n",
    "from src.util import read_numpy_array_from_disk, export_numpy_array_to_c_array\n",
    "\n",
    "# Ommiting tensorflow warnings\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data generated on part-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input json data file \n",
    "with open(data_file, 'r') as _in:\n",
    "    data = json.load(_in)\n",
    "\n",
    "# Reading x and y arrays\n",
    "output_dir = data['output_dir']\n",
    "\n",
    "# Directories Definition\n",
    "x_file_path = os.path.join(output_dir, data['x_file_name'])\n",
    "y_file_path = os.path.join(output_dir, data['y_file_name'])\n",
    "x_c_file_path = os.path.join(output_dir, 'x_data')\n",
    "y_c_file_path = os.path.join(output_dir, 'y_data')\n",
    "\n",
    "# Converting generated data to format compatible with Savime\n",
    "x_array = read_numpy_array_from_disk(x_file_path)\n",
    "y_array = read_numpy_array_from_disk(y_file_path)\n",
    "export_numpy_array_to_c_array(x_array, 'float64', x_c_file_path)\n",
    "export_numpy_array_to_c_array(y_array, 'float64', y_c_file_path)\n",
    "\n",
    "print('X values:\\n', x_array)\n",
    "print('Y values:\\n', y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the queries which we will run in Savime to build the necessary structures to create and load our datasets: CREATE_DATASET, CREATE_TAR and LOAD_SUBTAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the dataset to be used:\n",
    "num_observations = len(x_array)\n",
    "num_features     = x_array.shape[1]\n",
    "y_num_columns    = y_array.shape[1] if len(y_array.shape) == 2 else 1 \n",
    "\n",
    "x_dataset = pysavime.define.file_dataset('x', x_c_file_path, 'double', length=num_features)\n",
    "y_dataset = pysavime.define.file_dataset('y', y_c_file_path, 'double', length=y_num_columns)\n",
    "\n",
    "# Tar Definition \n",
    "index = pysavime.define.implicit_tar_dimension('index', 'int32', 1, num_observations)\n",
    "x = pysavime.define.tar_attribute('x', 'double', num_features)\n",
    "y = pysavime.define.tar_attribute('y', 'double', y_num_columns)\n",
    "tar = pysavime.define.tar('tutorialtar', [index], [x, y])\n",
    "\n",
    "# Definition of subtar loading commands\n",
    "subtar_index = pysavime.define.ordered_subtar_dimension(index, 1, num_observations)\n",
    "subtar_x = pysavime.define.subtar_attribute(x, x_dataset)\n",
    "subtar_y = pysavime.define.subtar_attribute(y, y_dataset)\n",
    "subtar = pysavime.define.subtar(tar, [subtar_index], [subtar_x, subtar_y])\n",
    "\n",
    "# The defined commands are:\n",
    "print(x_dataset.create_query_str(), y_dataset.create_query_str(), sep='\\n')\n",
    "print(tar.create_query_str())\n",
    "print(subtar.load_query_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the previously defined commands on savime \n",
    "\n",
    "1. We open and close the connection using Savime ('with' context)\n",
    "2. Creation of a command execution object, attached to the opened conection\n",
    "3. \n",
    " 1. Dataset Creation\n",
    " 2. Subtar Creation\n",
    " 3. Loading the datasets into the subtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pysavime.Client(host=savime_host, port=savime_port) as client:\n",
    "    client.execute(pysavime.operator.create(x_dataset))\n",
    "    client.execute(pysavime.operator.create(y_dataset))\n",
    "    client.execute(pysavime.operator.create(tar))\n",
    "    client.execute(pysavime.operator.load(subtar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each saved model, we get the prediction's mean squared error on the data domain. To do so, we\n",
    "execute the following steps:\n",
    "\n",
    "1. Register the model on the system: `pysavime.operator.register_model`\n",
    "2. Execute the predictive query: `pysavime.operator.predict`\n",
    "3. We calculate the squared difference between the query output and the true y value:\n",
    "`pysavime.operator.derive`\n",
    "4. From this value, we calculate the mean squared error: `pysavime.operator.aggregate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = {}\n",
    "registered_models = data['iid']\n",
    "\n",
    "with pysavime.Client(host=savime_host, port=savime_port) as client:\n",
    "    # dim_spec specifies the size of the predictive query window.\n",
    "    # It's a list of pairs, in which the first element specifies the dimension, \n",
    "    # and the second element specifies the number of observations        \n",
    "    dim_spec = [(index.name, num_observations)]\n",
    "    \n",
    "    for model_name, i in registered_models.items():\n",
    "        # A model is registered in Savime, i.e., we associate it with a Tar, identify what is the input attribute \n",
    "        # and the format of the multidimensional input array. In this case, we are sending the complete\n",
    "        # observations array, but it's also possible to predict only a section of it        \n",
    "        \n",
    "        # Register the model that we will use        \n",
    "        register_cmd = pysavime.operator.register_model(model_name=model_name, model_tar=tar.name, input_attribute=x.name,\n",
    "                                               dim_specification=dim_spec)\n",
    "        client.execute(register_cmd)\n",
    "        \n",
    "        # Calculate the mean squared error        \n",
    "        predict_cmd = pysavime.operator.predict(tar=tar.name, model_name=model_name, input_attribute=x.name)\n",
    "        derive_cmd = pysavime.operator.derive(predict_cmd, 'squared_difference', '(op_result - y)^2')\n",
    "        aggregate_cmd = pysavime.operator.aggregate(derive_cmd, 'avg', 'squared_difference', 'mse')\n",
    "        print(aggregate_cmd)\n",
    "        mse[model_name] = client.execute(aggregate_cmd)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we register each model's error and we build a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse[model_name])\n",
    "\n",
    "d = {key: value[0].attrs['mse'][0][0] for key, value in mse.items()}\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we display each model's mean squared error. \n",
    "Note that model 25 exhibits the best results, since it was trained in points from\n",
    "all of the partitions of the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering the dataframe\n",
    "df['index'] = df.index\n",
    "df['index'] = df['index'].apply(lambda x: int(x.split('_')[-1]))\n",
    "df = df.sort_values('index')\n",
    "\n",
    "# Graph display\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "sns.barplot(x='index', y=0, data=df, ax=ax, color='darkblue')\n",
    "\n",
    "# Adjusting the label\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Models')\n",
    "_ = plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
