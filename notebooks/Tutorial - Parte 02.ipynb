{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Necessário mudar o diretório de trabalho para o nível mais acima\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "# Inserir aqui o caminho da biblioteca do savime\n",
    "py_savime_path =  '/home/daniel/PycharmProjects/intelipetro/savime'\n",
    "sys.path.insert(0, py_savime_path)\n",
    "\n",
    "# Inserir aqui o caminho do arquivo de dados: um json contendo informações a respeito \n",
    "# da partição de x e y utilizada na parte 01.\n",
    "data_fp = 'saved_models/data.json'\n",
    "\n",
    "# Configuração do host e porta em que o SAVIME está escutando\n",
    "host = '127.0.0.1'\n",
    "port = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "\n",
    "from schema.tar import Tar, ImplicitTarDimensionSpecification, TarAttributeSpecification\n",
    "from savime.datatype import SavimeSupportedTypes\n",
    "from schema.schema import IntervalRange, IndexRange\n",
    "from schema.dataset import FileDataset\n",
    "from schema.subtar import OrderedSubTarDimensionSpecification, SubTarAttributeSpecification, SubTar\n",
    "from savime.client import Client\n",
    "from misc.command_runner import CommandRunner\n",
    "from util.converter import DataVariableBlockConverter\n",
    "from util.data_variable import DataVariableBlockOps\n",
    "\n",
    "from src.predictor_consumer import PredictionConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(data_fp, 'r') as _in:\n",
    "    data = json.load(_in)\n",
    "\n",
    "output_dir = data['output_dir']\n",
    "x_fp = os.path.join(output_dir, data['x_file_name'])\n",
    "y_fp = os.path.join(output_dir, data['y_file_name'])\n",
    "\n",
    "x = np.load(x_fp)\n",
    "y = np.load(y_fp)\n",
    "num_observations, num_features = x.shape\n",
    "y_num_columns = 1 if len(y.shape) == 1 else y.shape[1]\n",
    "\n",
    "x_c_fp = os.path.join(output_dir, 'x_data')\n",
    "y_c_fp = os.path.join(output_dir, 'y_data')\n",
    "\n",
    "# Salvar os arrays numpy em um formato legível ao SAVIME, isto é, como arrays (row-wise) e \n",
    "# sem metadados do numpy.\n",
    "x.astype('float64').tofile(x_c_fp)\n",
    "y.astype('float64').tofile(y_c_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_DATASET(\"x:double:2\", \"@/home/daniel/PycharmProjects/savime-notebooks/saved_models/x_data\");\n",
      "CREATE_DATASET(\"y:double:1\", \"@/home/daniel/PycharmProjects/savime-notebooks/saved_models/y_data\");\n"
     ]
    }
   ],
   "source": [
    "# Definição do datasets a serem utilizados:\n",
    "x_dataset = FileDataset(name='x', file_path=x_c_fp, data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                        is_in_savime_storage=False, num_columns=num_features)\n",
    "y_dataset = FileDataset(name='y', file_path=y_c_fp, data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                        is_in_savime_storage=False)\n",
    "\n",
    "# O comando gerado será:\n",
    "print(x_dataset.create_query_str(), y_dataset.create_query_str(), sep='\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_TAR(\"example\", \"*\", \"implicit, index, int32, 1, 1000000, 1\", \"x, double: 2 | y, double: 1\"  );\n"
     ]
    }
   ],
   "source": [
    "# Definição do Tar a ser empregado:\n",
    "index = ImplicitTarDimensionSpecification(name='index',\n",
    "                                          data_type=SavimeSupportedTypes.INT32,\n",
    "                                          interval=IntervalRange(1, num_observations, 1))\n",
    "\n",
    "x_attr = TarAttributeSpecification(name='x', data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                                   num_columns=num_features)\n",
    "\n",
    "y_attr = TarAttributeSpecification(name='y', data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                                   num_columns=y_num_columns)\n",
    "\n",
    "tar = Tar(name='example', dimension_specification=[index], attribute_specification=[x_attr, y_attr])\n",
    "\n",
    "# O comando gerado será:\n",
    "print(tar.create_query_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD_SUBTAR(\"example\", \"ordered, index, #1,#1000000\", \"x, x | y, y\")\n"
     ]
    }
   ],
   "source": [
    "# Carregamento do SubTar:\n",
    "\n",
    "sub_tar_index = OrderedSubTarDimensionSpecification(dimension=index,\n",
    "                                                    index_range=IndexRange(start=1, stop=num_observations,\n",
    "                                                                           is_physical=False))\n",
    "sub_tar_x = SubTarAttributeSpecification(attribute=x_attr, dataset=x_dataset)\n",
    "sub_tar_y = SubTarAttributeSpecification(attribute=y_attr, dataset=y_dataset)\n",
    "\n",
    "sub_tar = SubTar(tar=tar, dimension_specification=[sub_tar_index], attribute_specification=[sub_tar_x, sub_tar_y])\n",
    "\n",
    "# O comando gerado será:\n",
    "print(sub_tar.load_query_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para executar os passos a seguir é necessário que haja um servidor SAVIME escutando no host e porta definidos anteriormente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-02 22:30:40 [Connector]:DEBUG: Trying to open a connection on the port 65000.\n",
      "2020-02-02 22:30:40 [Connector]:INFO: A connection has been opened on the port 65000.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Running the query CREATE_DATASET(\"x:double:2\", \"@/home/daniel/PycharmProjects/savime-notebooks/saved_models/x_data\");.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Query handler response message: Query executed successfully\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.000004s to run `Client.process_query_response`.\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.133196s to run `Client.execute`.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Running the query CREATE_DATASET(\"y:double:1\", \"@/home/daniel/PycharmProjects/savime-notebooks/saved_models/y_data\");.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Query handler response message: Query executed successfully\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.000005s to run `Client.process_query_response`.\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.104437s to run `Client.execute`.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Running the query CREATE_TAR(\"example\", \"*\", \"implicit, index, int32, 1, 1000000, 1\", \"x, double: 2 | y, double: 1\"  );.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Query handler response message: Query executed successfully\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.000005s to run `Client.process_query_response`.\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.096251s to run `Client.execute`.\n",
      "2020-02-02 22:30:40 [Client]:INFO: Running the query LOAD_SUBTAR(\"example\", \"ordered, index, #1,#1000000\", \"x, x | y, y\").\n",
      "2020-02-02 22:30:40 [Client]:INFO: Query handler response message: Query executed successfully\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.000005s to run `Client.process_query_response`.\n",
      "2020-02-02 22:30:40 [Timer]:INFO: It took 0.094305s to run `Client.execute`.\n",
      "2020-02-02 22:30:40 [Connector]:DEBUG: Trying to close a connection on the port 65000.\n",
      "2020-02-02 22:30:40 [Connector]:INFO: A connection has been closed on the port 65000.\n"
     ]
    }
   ],
   "source": [
    "# 1. Conexão é aberta e fechada com o SAVIME (contexto with)\n",
    "# 2. Criação de um objeto de execução de comandos vinculado à conexão criada.\n",
    "# 3. a) Criação dos datasets\n",
    "#    b) Criação do subtar\n",
    "#    c) Carregamento dos datasets por meio de um subtar\n",
    "\n",
    "with Client(host=host, port=port) as client:\n",
    "    command_runner = CommandRunner(client)\n",
    "    \n",
    "    command_runner.create(x_dataset)\n",
    "    command_runner.create(y_dataset)\n",
    "    command_runner.create(tar)\n",
    "    command_runner.load(sub_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-02 22:30:44 [Connector]:DEBUG: Trying to open a connection on the port 65000.\n",
      "2020-02-02 22:30:44 [Connector]:INFO: A connection has been opened on the port 65000.\n",
      "2020-02-02 22:30:44 [Client]:INFO: Running the query SELECT(example).\n",
      "2020-02-02 22:30:44 [Client]:INFO: Query handler response message: #index,d,int32|x,a,double:2:2|y,a,double:1\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Trying to receive a buffer with 4000000 bytes.\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Trying to receive a buffer with 16000000 bytes.\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Trying to receive a buffer with 8000000 bytes.\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Block received.\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Returning an array with 1000000 rows.\n",
      "2020-02-02 22:30:44 [Client]:DEBUG: Read query block returned: SAV_NO_MORE_BLOCKS.\n",
      "2020-02-02 22:30:44 [Timer]:INFO: It took 0.042226s to run `Client.process_query_response`.\n",
      "2020-02-02 22:30:44 [Timer]:INFO: It took 0.131165s to run `Client.execute`.\n",
      "2020-02-02 22:30:44 [Connector]:DEBUG: Trying to close a connection on the port 65000.\n",
      "2020-02-02 22:30:44 [Connector]:INFO: A connection has been closed on the port 65000.\n",
      "2020-02-02 22:30:44 [Timer]:INFO: It took 0.008970s to run `DataVariableBlockOps.concatenate`.\n",
      "2020-02-02 22:30:46 [Timer]:INFO: It took 2.044922s to run `DataVariableBlockToXarrayDataset.__call__`.\n",
      "2020-02-02 22:30:46 [Timer]:INFO: It took 0.021562s to run `DataVariableBlockToPandasDataFrame.__call__`.\n"
     ]
    }
   ],
   "source": [
    "# Os objetos abaixo são utilizados para converter do container mais genérico DataVariableBlock\n",
    "# para xarray e pandas. DataVariableBlocks contêm dois atributos: dims e attrs. Cada um desses contém \n",
    "# uma dicionário do tipo nome_array: array, onde array é um numpy array.\n",
    "\n",
    "xarray_converter = DataVariableBlockConverter('xarray')\n",
    "pandas_converter = DataVariableBlockConverter('pandas')\n",
    "\n",
    "# Efetuar select no SAVIME a fim de verificar se o TAR for criado de forma adequada\n",
    "with Client(host=host, port=port) as client:\n",
    "    responses = client.execute(f'SELECT({tar.name})')\n",
    "        \n",
    "# Em geral, o retorno do SAVIME a uma consulta é dado por subtar. Ou seja, se o tar contem n subtars então\n",
    "# a variável responses acima será uma lista com n DataVariableBlocks. Abaixo, eles são concatenados.\n",
    "data_variable_block = DataVariableBlockOps.concatenate(responses)\n",
    "\n",
    "# E abaixo convertidos\n",
    "xdataset_response = xarray_converter(data_variable_block)\n",
    "pandas_response = pandas_converter(data_variable_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (_0_: 2, index: 1000000)\n",
      "Coordinates:\n",
      "  * index    (index) int32 1 2 3 4 5 6 ... 999996 999997 999998 999999 1000000\n",
      "  * _0_      (_0_) int64 0 1\n",
      "    _mask_   (index, _0_) bool True True True True True ... True True True True\n",
      "Data variables:\n",
      "    x        (index, _0_) float64 -1.0 -1.0 -1.0 -1.0 -1.0 ... 1.0 1.0 1.0 1.0\n",
      "    y        (index) float64 -2.176 -2.176 -2.176 -2.176 ... 5.824 5.824 5.824\n",
      "\n",
      "                x                   y\n",
      "                0         1         0\n",
      "index                                \n",
      "1       -0.999999 -0.999998 -2.175664\n",
      "2       -0.999998 -0.999998 -2.175662\n",
      "3       -0.999996 -0.999995 -2.175659\n",
      "4       -0.999995 -0.999995 -2.175657\n",
      "5       -0.999994 -0.999994 -2.175655\n",
      "...           ...       ...       ...\n",
      "999996   0.999989  0.999990  5.824268\n",
      "999997   0.999991  0.999992  5.824283\n",
      "999998   0.999993  0.999996  5.824298\n",
      "999999   0.999996  0.999997  5.824313\n",
      "1000000  0.999998  1.000000  5.824326\n",
      "\n",
      "[1000000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Como xarray representa arrays como matrizes multidimensionais densas e SAVIME é mais genérico, \n",
    "# abarcando matrizes esparsas, é preciso manter uma máscara _mask_ identificando se determinado\n",
    "# elemento na matriz está presente ou não.\n",
    "print(xdataset_response)\n",
    "print()\n",
    "print(pandas_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas ok: True\n",
      "xarray ok: True\n"
     ]
    }
   ],
   "source": [
    "# Checando se a resposta é correta\n",
    "print('pandas ok:', np.allclose(x, pandas_response['x'].values.reshape(x.shape)))\n",
    "\n",
    "print('xarray ok:', \n",
    "np.allclose(x,\n",
    "xdataset_response['x'].values[xdataset_response['_mask_']].reshape(x.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para executar os passos abaixo é nessário que o servidor de modelos esteja rodando.**\n",
    "Execute o comando abaixo:\n",
    "`tensorflow_model_server --rest_api_port=8501 --model_config_file=ARQUIVO_DE_MODELOS` \n",
    "Note que você deve trocar ARQUIVO_DE_MODELOS pelo caminho do arquivo no qual os modelos foram registrados. Esse arquivo é o `models.config` dentro da pasta `saved_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O MSE de my_elastic_net_0: 6.058782 (dado por tfx) e 6.058782 (computado anteriormente).\n",
      "O MSE de my_elastic_net_1: 10.206772 (dado por tfx) e 10.206772 (computado anteriormente).\n",
      "O MSE de my_elastic_net_2: 5.071167 (dado por tfx) e 5.071167 (computado anteriormente).\n",
      "O MSE de my_elastic_net_3: 5.688607 (dado por tfx) e 5.688607 (computado anteriormente).\n",
      "O MSE de my_elastic_net_4: 5.503781 (dado por tfx) e 5.503781 (computado anteriormente).\n",
      "O MSE de my_elastic_net_5: 4.729437 (dado por tfx) e 4.729437 (computado anteriormente).\n",
      "O MSE de my_elastic_net_6: 4.835845 (dado por tfx) e 4.835845 (computado anteriormente).\n",
      "O MSE de my_elastic_net_7: 4.148883 (dado por tfx) e 4.148883 (computado anteriormente).\n",
      "O MSE de my_elastic_net_8: 3.702509 (dado por tfx) e 3.702509 (computado anteriormente).\n",
      "O MSE de my_elastic_net_9: 4.101842 (dado por tfx) e 4.101842 (computado anteriormente).\n",
      "O MSE de my_elastic_net_10: 3.684451 (dado por tfx) e 3.684451 (computado anteriormente).\n",
      "O MSE de my_elastic_net_11: 8.520635 (dado por tfx) e 8.520635 (computado anteriormente).\n",
      "O MSE de my_elastic_net_12: 5.794629 (dado por tfx) e 5.794629 (computado anteriormente).\n",
      "O MSE de my_elastic_net_13: 11.385506 (dado por tfx) e 11.385506 (computado anteriormente).\n",
      "O MSE de my_elastic_net_14: 3.376288 (dado por tfx) e 3.376288 (computado anteriormente).\n",
      "O MSE de my_elastic_net_15: 3.708067 (dado por tfx) e 3.708067 (computado anteriormente).\n",
      "O MSE de my_elastic_net_16: 4.015556 (dado por tfx) e 4.015556 (computado anteriormente).\n",
      "O MSE de my_elastic_net_17: 4.240202 (dado por tfx) e 4.240202 (computado anteriormente).\n",
      "O MSE de my_elastic_net_18: 4.416659 (dado por tfx) e 4.416659 (computado anteriormente).\n",
      "O MSE de my_elastic_net_19: 4.498301 (dado por tfx) e 4.498301 (computado anteriormente).\n"
     ]
    }
   ],
   "source": [
    "tfx_host = 'localhost'\n",
    "tfx_port = 8501\n",
    "model_names = data['splits'].keys()\n",
    "\n",
    "# Ordena os nomes 0, 1, 2, 3,...\n",
    "def get_int_part(n):\n",
    "    return int(re.findall('\\d+', n)[0])\n",
    "model_names = sorted(model_names, key=lambda x: get_int_part(x))\n",
    "\n",
    "mse_array = np.load(os.path.join(output_dir, 'mse_array.npy')).ravel()\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # O objeto abaixo é vinculado ao model (dado por model_name)\n",
    "    model_predictive_service = PredictionConsumer(host=tfx_host, port=tfx_port, model_name=model_name)\n",
    "    # Abaixo é enviado o array x como consulta preditiva, e retornado y_hat\n",
    "    y_hat = model_predictive_service.predict(x)\n",
    "    \n",
    "    model_mse = mean_squared_error(y, y_hat)\n",
    "    print(f'O MSE de {model_name}: {model_mse:4f} (dado por tfx) e {mse_array[i]:4f} (computado anteriormente).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abaixo não está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-02 22:32:19 [Connector]:DEBUG: Trying to open a connection on the port 65000.\n",
      "2020-02-02 22:32:19 [Connector]:INFO: A connection has been opened on the port 65000.\n",
      "2020-02-02 22:32:19 [Client]:INFO: Running the query REGISTER_MODEL(my_elastic_net_0, example, x, \"index-1000\");.\n",
      "2020-02-02 22:32:20 [Client]:INFO: Query handler response message: Query executed successfully\n",
      "2020-02-02 22:32:20 [Timer]:INFO: It took 0.000002s to run `Client.process_query_response`.\n",
      "2020-02-02 22:32:20 [Timer]:INFO: It took 0.087964s to run `Client.execute`.\n",
      "2020-02-02 22:32:20 [Client]:INFO: Running the query PREDICT(example, my_elastic_net_0, x);.\n",
      "2020-02-02 22:32:20 [Client]:INFO: Query handler response message: #index,d,int32|x,a,double:2:2|y,a,double:1|op_result,a,double:1\n",
      "2020-02-02 22:32:25 [Client]:DEBUG: Read query block returned: SAV_ERROR_RESPONSE_BLOCKS.\n",
      "2020-02-02 22:32:25 [Timer]:INFO: It took 5.748627s to run `Client.process_query_response`.\n",
      "2020-02-02 22:32:25 [Timer]:INFO: It took 5.841233s to run `Client.execute`.\n",
      "2020-02-02 22:32:25 [Connector]:DEBUG: Trying to close a connection on the port 65000.\n",
      "2020-02-02 22:32:25 [Connector]:INFO: A connection has been closed on the port 65000.\n"
     ]
    }
   ],
   "source": [
    "model = model_names[0]\n",
    "\n",
    "with Client(host=host, port=port) as client:\n",
    "    command_runner = CommandRunner(client)\n",
    "    command_runner.register_model(model_name=model, model_tar=tar.name,\n",
    "                                  target_attribute=x_attr.name,\n",
    "                                  dim_specification={index.name: 1000})\n",
    "    command_runner.predict(tar=tar.name, model_name=model, target_attribute=x_attr.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
