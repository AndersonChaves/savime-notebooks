{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Necessário mudar o diretório de trabalho para o nível mais acima\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "# Inserir aqui o caminho da biblioteca do savime\n",
    "py_savime_path =  '/home/daniel/PycharmProjects/intelipetro/savime'\n",
    "sys.path.insert(0, py_savime_path)\n",
    "\n",
    "# Inserir aqui o caminho do arquivo de dados: um json contendo informações a respeito \n",
    "# da partição de x e y utilizada na parte 01.\n",
    "data_fp = 'saved_models/data.json'\n",
    "\n",
    "# Configuração do host e porta em que o SAVIME está escutando\n",
    "host = '127.0.0.1'\n",
    "port = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "\n",
    "from schema.tar import Tar, ImplicitTarDimensionSpecification, TarAttributeSpecification\n",
    "from savime.datatype import SavimeSupportedTypes\n",
    "from schema.schema import IntervalRange, IndexRange\n",
    "from schema.dataset import FileDataset\n",
    "from schema.subtar import OrderedSubTarDimensionSpecification, SubTarAttributeSpecification, SubTar\n",
    "from savime.client import Client\n",
    "from misc.command_runner import CommandRunner\n",
    "from util.converter import DataVariableBlockConverter\n",
    "from util.data_variable import DataVariableBlockOps\n",
    "\n",
    "from src.predictor_consumer import PredictionConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(data_fp, 'r') as _in:\n",
    "    data = json.load(_in)\n",
    "\n",
    "output_dir = data['output_dir']\n",
    "x_fp = os.path.join(output_dir, data['x_file_name'])\n",
    "y_fp = os.path.join(output_dir, data['y_file_name'])\n",
    "\n",
    "x = np.load(x_fp)\n",
    "y = np.load(y_fp)\n",
    "num_observations, num_features = x.shape\n",
    "y_num_columns = 1 if len(y.shape) == 1 else y.shape[1]\n",
    "\n",
    "x_c_fp = os.path.join(output_dir, 'x_data')\n",
    "y_c_fp = os.path.join(output_dir, 'y_data')\n",
    "\n",
    "# Salvar os arrays numpy em um formato legível ao SAVIME, isto é, como arrays (row-wise) e \n",
    "# sem metadados do numpy.\n",
    "x.astype('float64').tofile(x_c_fp)\n",
    "y.astype('float64').tofile(y_c_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Definição do datasets a serem utilizados:\n",
    "x_dataset = FileDataset(name='x', file_path=x_c_fp, data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                        is_in_savime_storage=False, num_columns=num_features)\n",
    "y_dataset = FileDataset(name='y', file_path=y_c_fp, data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                        is_in_savime_storage=False)\n",
    "\n",
    "# O comando gerado será:\n",
    "print(x_dataset.create_query_str(), y_dataset.create_query_str(), sep='\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Definição do Tar a ser empregado:\n",
    "index = ImplicitTarDimensionSpecification(name='index',\n",
    "                                          data_type=SavimeSupportedTypes.INT32,\n",
    "                                          interval=IntervalRange(1, num_observations, 1))\n",
    "\n",
    "x_attr = TarAttributeSpecification(name='x', data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                                   num_columns=num_features)\n",
    "\n",
    "y_attr = TarAttributeSpecification(name='y', data_type=SavimeSupportedTypes.DOUBLE,\n",
    "                                   num_columns=y_num_columns)\n",
    "\n",
    "tar = Tar(name='example', dimension_specification=[index], attribute_specification=[x_attr, y_attr])\n",
    "\n",
    "# O comando gerado será:\n",
    "print(tar.create_query_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Carregamento do SubTar:\n",
    "\n",
    "sub_tar_index = OrderedSubTarDimensionSpecification(dimension=index,\n",
    "                                                    index_range=IndexRange(start=1, stop=num_observations,\n",
    "                                                                           is_physical=False))\n",
    "sub_tar_x = SubTarAttributeSpecification(attribute=x_attr, dataset=x_dataset)\n",
    "sub_tar_y = SubTarAttributeSpecification(attribute=y_attr, dataset=y_dataset)\n",
    "\n",
    "sub_tar = SubTar(tar=tar, dimension_specification=[sub_tar_index], attribute_specification=[sub_tar_x, sub_tar_y])\n",
    "\n",
    "# O comando gerado será:\n",
    "print(sub_tar.load_query_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para executar os passos a seguir é necessário que haja um servidor SAVIME escutando no host e porta definidos anteriormente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Conexão é aberta e fechada com o SAVIME (contexto with)\n",
    "# 2. Criação de um objeto de execução de comandos vinculado à conexão criada.\n",
    "# 3. a) Criação dos datasets\n",
    "#    b) Criação do subtar\n",
    "#    c) Carregamento dos datasets por meio de um subtar\n",
    "\n",
    "with Client(host=host, port=port) as client:\n",
    "    command_runner = CommandRunner(client)\n",
    "    \n",
    "    command_runner.create(x_dataset)\n",
    "    command_runner.create(y_dataset)\n",
    "    command_runner.create(tar)\n",
    "    command_runner.load(sub_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Os objetos abaixo são utilizados para converter do container mais genérico DataVariableBlock\n",
    "# para xarray e pandas. DataVariableBlocks contêm dois atributos: dims e attrs. Cada um desses contém \n",
    "# uma dicionário do tipo nome_array: array, onde array é um numpy array.\n",
    "\n",
    "xarray_converter = DataVariableBlockConverter('xarray')\n",
    "pandas_converter = DataVariableBlockConverter('pandas')\n",
    "\n",
    "# Efetuar select no SAVIME a fim de verificar se o TAR for criado de forma adequada\n",
    "with Client(host=host, port=port) as client:\n",
    "    responses = client.execute(f'SELECT({tar.name})')\n",
    "        \n",
    "# Em geral, o retorno do SAVIME a uma consulta é dado por subtar. Ou seja, se o tar contem n subtars então\n",
    "# a variável responses acima será uma lista com n DataVariableBlocks. Abaixo, eles são concatenados.\n",
    "data_variable_block = DataVariableBlockOps.concatenate(responses)\n",
    "\n",
    "# E abaixo convertidos\n",
    "xdataset_response = xarray_converter(data_variable_block)\n",
    "pandas_response = pandas_converter(data_variable_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como xarray representa arrays como matrizes multidimensionais densas e SAVIME é mais genérico, \n",
    "# abarcando matrizes esparsas, é preciso manter uma máscara _mask_ identificando se determinado\n",
    "# elemento na matriz está presente ou não.\n",
    "print(xdataset_response)\n",
    "print()\n",
    "print(pandas_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se a resposta é correta\n",
    "print('pandas ok:', np.allclose(x, pandas_response['x'].values.reshape(x.shape)))\n",
    "\n",
    "print('xarray ok:', \n",
    "np.allclose(x,\n",
    "xdataset_response['x'].values[xdataset_response['_mask_']].reshape(x.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para executar os passos abaixo é nessário que o servidor de modelos esteja rodando.**\n",
    "Execute o comando abaixo:\n",
    "`tensorflow_model_server --rest_api_port=8501 --model_config_file=ARQUIVO_DE_MODELOS` \n",
    "Note que você deve trocar ARQUIVO_DE_MODELOS pelo caminho do arquivo no qual os modelos foram registrados. Esse arquivo é o `models.config` dentro da pasta `saved_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfx_host = 'localhost'\n",
    "tfx_port = 8501\n",
    "model_names = data['splits'].keys()\n",
    "\n",
    "# Ordena os nomes 0, 1, 2, 3,...\n",
    "def get_int_part(n):\n",
    "    return int(re.findall('\\d+', n)[0])\n",
    "model_names = sorted(model_names, key=lambda x: get_int_part(x))\n",
    "\n",
    "mse_array = np.load(os.path.join(output_dir, 'mse_array.npy')).ravel()\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # O objeto abaixo é vinculado ao model (dado por model_name)\n",
    "    model_predictive_service = PredictionConsumer(host=tfx_host, port=tfx_port, model_name=model_name)\n",
    "    # Abaixo é enviado o array x como consulta preditiva, e retornado y_hat\n",
    "    y_hat = model_predictive_service.predict(x)\n",
    "    \n",
    "    model_mse = mean_squared_error(y, y_hat)\n",
    "    print(f'O MSE de {model_name}: {model_mse:4f} (dado por tfx) e {mse_array[i]:4f} (computado anteriormente).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abaixo não está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_names[0]\n",
    "\n",
    "with Client(host=host, port=port) as client:\n",
    "    command_runner = CommandRunner(client)\n",
    "    command_runner.register_model(model_name=model, model_tar=tar.name,\n",
    "                                  target_attribute=x_attr.name,\n",
    "                                  dim_specification={index.name: 1000})\n",
    "    command_runner.predict(tar=tar.name, model_name=model, target_attribute=x_attr.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
