{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 02\n",
    "\n",
    "Nessa parte, os modelos criados anteriormente serão utilizados para realizar predições. Para isso, eles devem ser registrados no TFX. Para efetuar as predições, os dados utilizados no treinamento desses modelos serão inseridos no SAVIME, o qual ficará encarregado de enviar e receber os dados para/de TFX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Necessário mudar o diretório de trabalho para o nível mais acima\n",
    "if not 'notebooks' in os.listdir('.'):\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "# Inserir aqui o caminho do arquivo de dados: um json contendo informações a respeito \n",
    "# da partição de x e y utilizada na parte 01.\n",
    "data_fp = 'saved_models_elastic_net/data.json'\n",
    "\n",
    "# Configuração do host e porta em que o SAVIME está escutando\n",
    "host = '127.0.0.1'\n",
    "port = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
    "import seaborn as sns\n"
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Savime imports\n",
    "import pysavime\n",
    "from pysavime.util.data_variable import DataVariableBlock, DataVariableBlockOps\n",
    "from pysavime.util.converter import DataVariableBlockConverter\n",
    "\n",
    "from src.predictor_consumer import PredictionConsumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é carregar os dados gerados anteriormente. Um dos motivos é remover os metadados dos arrays de entrada e saída. Em outras palavras, tornar os arrays numpy em vetores contíguos do C/C++. Esses vetores serão posteriormente cadastrados no SAVIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(data_fp, 'r') as _in:\n",
    "    data = json.load(_in)\n",
    "\n",
    "output_dir = data['output_dir']\n",
    "x_fp = os.path.join(output_dir, data['x_file_name'])\n",
    "y_fp = os.path.join(output_dir, data['y_file_name'])\n",
    "\n",
    "x_array = np.load(x_fp)\n",
    "y_array = np.load(y_fp)\n",
    "num_observations, num_features = x_array.shape\n",
    "y_num_columns = 1 if len(y_array.shape) == 1 else y_array.shape[1]\n",
    "\n",
    "x_c_fp = os.path.join(output_dir, 'x_data')\n",
    "y_c_fp = os.path.join(output_dir, 'y_data')\n",
    "\n",
    "# Salvar os arrays numpy em um formato \"legível\" ao SAVIME, isto é, como arrays (row-wise) e \n",
    "# sem metadados do numpy.\n",
    "x_array.astype('float64').tofile(x_c_fp)\n",
    "y_array.astype('float64').tofile(y_c_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Definição de esquemas\n",
    "\n",
    "**Vamos agora definir os esquemas dos dados no sistema SAVIME.**\n",
    "\n",
    "Grosso modo, SAVIME é um SGDB para matrizes multidimensionais. O elemento base de seu modelo de dados é o Tar. Pode-se pensar em um Tar como sendo um dataset de matrizes muldimensionais com dimensões nomeadas. Por exemplo, determinado tar pode possuir 3 dimensões nomeadas (tempo, latitude e longitude) e 2 atributos (temperatura e precipitação). Nesse caso, o tar conteria duas matrizes multidimensionais de terceira ordem, onde cada ponto (tempo, latitude, longitude) representa uma informação climática em determinado instante e local. Além do tar outros dois elementos são importantes no modelo de dados do SAVIME: dataset e subtar. O primeiro diz respeito ao array (atributo que está de fato armazenado em disco). Por sua vez, cada subtar é associado a um único tar e diz respeito a como um array/conjunto de arrays é carregado no tar.\n",
    "\n",
    "A fim de tornar o processo de comunicação com o sistema facilitado nesse notebook são empregadas as funções da API PySavime. Essa API permite que as consultas sejam realizadas diretamente do ambiente Python e que os próprios resultados dessas consultas sejam elementos facilmente integrados no ciclo de desenvolvimento de modelos, como arrays numpy e dataframes pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Definição do datasets a serem utilizados:\n",
    "# Lembre que tinha X tem duas features (length)\n",
    "\n",
    "x_dataset = pysavime.define.file_dataset('x', x_c_fp, 'double', length=num_features)\n",
    "y_dataset = pysavime.define.file_dataset('y', y_c_fp, 'double')\n",
    "\n",
    "# O comando gerado será:\n",
    "print(x_dataset.create_query_str(), y_dataset.create_query_str(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Definição do Tar a ser empregado:\n",
    "\n",
    "# Dimensão index\n",
    "index = pysavime.define.implicit_tar_dimension('index', 'int32', 1, num_observations)\n",
    "x = pysavime.define.tar_attribute('x', 'double', num_features)\n",
    "y = pysavime.define.tar_attribute('y', 'double', y_num_columns)\n",
    "tar = pysavime.define.tar('tutorial', [index], [x, y])\n",
    "\n",
    "# O comando gerado será:\n",
    "print(tar.create_query_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Carregamento do SubTar:\n",
    "# Aqui de fato os dados serão carregados no Tar.  \n",
    "\n",
    "subtar_index = pysavime.define.ordered_subtar_dimension(index, 1, num_observations)\n",
    "subtar_x = pysavime.define.subtar_attribute(x, x_dataset)\n",
    "subtar_y = pysavime.define.subtar_attribute(y, y_dataset)\n",
    "subtar = pysavime.define.subtar(tar, [subtar_index], [subtar_x, subtar_y])\n",
    "\n",
    "print(subtar.load_query_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Instanciação do servidor SAVIME e execução de consultas\n",
    "\n",
    "\n",
    "### Para executar os passos a seguir é necessário que haja um servidor SAVIME escutando no host e porta definidos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Conexão é aberta e fechada com o SAVIME (contexto with)\n",
    "# 2. Criação de um objeto de execução de comandos vinculado à conexão criada.\n",
    "# 3. a) Criação dos datasets\n",
    "#    b) Criação do subtar\n",
    "#    c) Carregamento dos datasets por meio de um subtar\n",
    "\n",
    "with pysavime.Client(host=host, port=port) as client:\n",
    "    client.execute(pysavime.operator.create(x_dataset))\n",
    "    client.execute(pysavime.operator.create(y_dataset))\n",
    "    client.execute(pysavime.operator.create(tar))\n",
    "    client.execute(pysavime.operator.load(subtar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Os objetos abaixo são utilizados para converter do container mais genérico DataVariableBlock, retornado \n",
    "# como resposta da consulta, em  elmentos xarray e pandas. \n",
    "# Note que DataVariableBlocks contêm dois atributos: dims e attrs. Cada um desses contém um\n",
    "# dicionário do tipo nome_array: array, onde array é um numpy array.\n",
    "\n",
    "xarray_converter = DataVariableBlockConverter('xarray')\n",
    "pandas_converter = DataVariableBlockConverter('pandas')\n",
    "\n",
    "# Efetuar select no SAVIME a fim de verificar se o TAR for criado de forma adequada\n",
    "with pysavime.Client(host=host, port=port) as client:\n",
    "    responses = client.execute(pysavime.operator.select(tar))\n",
    "        \n",
    "# Em geral, o retorno do SAVIME a uma consulta é dado por subtar. Ou seja, se o tar contem n subtars então\n",
    "# a variável responses acima será uma lista com n DataVariableBlocks. Abaixo, eles são concatenados.\n",
    "data_variable_block = DataVariableBlockOps.concatenate(responses)\n",
    "\n",
    "# E abaixo convertidos\n",
    "xdataset_response = xarray_converter(data_variable_block)\n",
    "pandas_response = pandas_converter(data_variable_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Obs.: \n",
    "# 1) Como xarray representa arrays como matrizes multidimensionais densas e SAVIME é mais genérico, \n",
    "# abarcando matrizes esparsas, é preciso manter uma máscara _mask_ identificando se determinado\n",
    "# elemento na matriz está presente ou não.\n",
    "# 2) Dataframes pandas é intrinsicamente uma estrutura tabular. Para permitir a representação de atributos\n",
    "# com uma segunda dimensão (matrizes) emprega-se índices múltiplos. Note a coluna x abaixo.\n",
    "print('XDATASET')\n",
    "print(xdataset_response)\n",
    "print('DATAFRAME')\n",
    "print(pandas_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Checando se a resposta é correta\n",
    "print('pandas ok:', np.allclose(x_array, pandas_response['x'].values.reshape(x_array.shape)))\n",
    "\n",
    "print('xarray ok:', \n",
    "np.allclose(x_array,\n",
    "xdataset_response['x'].values[xdataset_response['_mask_']].reshape(x_array.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Instanciação TFX e execução de consultas preditivas\n",
    "\n",
    "### Para executar os passos abaixo é nessário que o servidor de modelos esteja rodando.\n",
    "\n",
    "Execute o comando abaixo:\n",
    "`tensorflow_model_server --rest_api_port=8501 --model_config_file=ARQUIVO_DE_MODELOS` \n",
    "Note que você deve trocar ARQUIVO_DE_MODELOS pelo caminho do arquivo no qual os modelos foram registrados. Esse arquivo é o `models.config` dentro da pasta `saved_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tfx_host = 'localhost'\n",
    "tfx_port = 8501\n",
    "\n",
    "previously_computed_mse = np.array(data['metrics']['mean_squared_error'])\n",
    "model_name_to_iid = data['iid']\n",
    "whole_partition_iid = model_name_to_iid[data['model']]\n",
    "\n",
    "mse = {}\n",
    "\n",
    "for model_name, i in model_name_to_iid.items():\n",
    "    # O objeto abaixo é vinculado ao model (dado por model_name)\n",
    "    model_predictive_service = PredictionConsumer(host=tfx_host, port=tfx_port, model_name=model_name)\n",
    "    \n",
    "    # Abaixo é enviado o array x como consulta preditiva, e retornado y_hat\n",
    "    y_array_hat = model_predictive_service.predict(x_array)\n",
    "    \n",
    "    # Computando o mse com o resultado retornardo por TFX.\n",
    "    model_mse = mean_squared_error(y_array, y_array_hat)\n",
    "    \n",
    "    mse[i] = {'TFX': model_mse, 'Antes': previously_computed_mse[i][whole_partition_iid]}\n",
    "\n",
    "\n",
    "def get_df_for_checking_result(result):\n",
    "    df = pd.DataFrame.from_dict(mse, orient='index')\n",
    "    df['Está Correto'] = np.isclose(df['TFX'].values, df['Antes'].values)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index.name = 'Model IID'\n",
    "    return df\n",
    "\n",
    "get_df_for_checking_result(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora ao invés de solicitar a predição diretamente ao TFX (model_predictive_service empregado anteriormente), utilizaremos o SAVIME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Uso do SAVIME na execução de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mse = {}\n",
    "registered_models = data['iid']\n",
    "\n",
    "with pysavime.Client(host=savime_host, port=savime_port) as client:\n",
    "    # dim_spec especifica o tamanho da janela preditiva\n",
    "    # É uma lista de pares, nos quais o primeiro elemento especifica a dimensão,\n",
    "    # e o segundo elemento especifica o número de observações\n",
    "    \n",
    "    input_dim_spec = [(index.name, num_observations)]\n",
    "    output_dim_spec = [(index.name, num_observations)]\n",
    "    for model_name, i in registered_models.items():\n",
    "        # Um modelo é registrado no Savime, i.e., associado a um TAR, identificando qual o atributo e \n",
    "        # formato do TAR de entrada, bem como o formato do TAR de saída. Nesse caso, iremos realizar a \n",
    "        # previsão sobre um TAR completo, mas é possível selecionar apenas uma subseção deste\n",
    "        \n",
    "    \n",
    "        # Registra o modelo que utilizaremos\n",
    "        register_cmd = pysavime.operator.register_model(model_identifier=model_name, \n",
    "                                                        input_dim_specification=input_dim_spec, \n",
    "                                                        output_dim_specification=output_dim_spec,\n",
    "                                                        attribute_specification=[x.name])\n",
    "        print(register_cmd)\n",
    "        client.execute(register_cmd)\n",
    "                \n",
    "        # Calcula o erro médio quadrático\n",
    "        predict_cmd = pysavime.operator.predict(tar=tar.name, model_identifier=model_name)        \n",
    "        print(predict_cmd)\n",
    "        predict_result = client.execute(predict_cmd) \n",
    "        \n",
    "        # Para cada resultado do predict\n",
    "        # Calcular (result - y)^2 \n",
    "        mean_squared_error = 0\n",
    "        y_index = 0\n",
    "        for result in predict_result[0][1]['op_result']:\n",
    "            mean_squared_error = mean_squared_error + (result - y_array[y_index])**2\n",
    "            y_index += 1            \n",
    "        mean_squared_error = mean_squared_error / num_observations\n",
    "        print(mean_squared_error)    \n",
    "        mse[model_name] = mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mse.keys())\n",
    "\n",
    "d = {key: value for key, value in mse.items()}\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o dataframe\n",
    "df['index'] = df.index\n",
    "df['index'] = df['index'].apply(lambda x: int(x.split('_')[-1]))\n",
    "df = df.sort_values('index')\n",
    "\n",
    "# Configura o gráfico\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "sns.barplot(x='index', y=0, data=df, ax=ax, color='darkblue')\n",
    "\n",
    "# Ajusta a legenda\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Models')\n",
    "_ = plt.ylabel('MSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
